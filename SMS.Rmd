---
title: "SMS"
output:
  word_document: default
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
## Import all the libraries
```{r}
importlib <- c("ggplot2", "stringr", "magrittr", "futile.logger", "VennDiagram", "tm", "SnowballC", "wordcloud", "RColorBrewer", "lattice", "caret", "rpart", "rpart.plot", "randomForest", "e1071", "ROCR", "gmodels", "mime", "plotly")

require(importlib)

lapply(importlib, require, character.only = TRUE)
```

## Download the dataset.
```{r}
Spam_SMS <- read.csv("./SMS_Spam_Dataset.csv", stringsAsFactors = F)
str(Spam_SMS)
```

## Clean the data. 

```{r}
# Remove Null Columns.
Spam_SMS$X <- NULL
Spam_SMS$X.1 <- NULL
Spam_SMS$X.2 <- NULL

#Assign appropriate names to the columns.
names(Spam_SMS) <- c("MessageLabel","Message")

#Check if any other NULL values exist in the dataset.
colSums(is.na(Spam_SMS))

#Convert class into factor.
levels(as.factor(Spam_SMS$MessageLabel))

#Assign appropriate names to the data entries under Column "Message_Label"
Spam_SMS$MessageLabel[Spam_SMS$MessageLabel == "ham"] <- "Legitimate"
Spam_SMS$MessageLabel[Spam_SMS$MessageLabel == "spam"] <- "Spam"

#Convert class into factor.
Spam_SMS$MessageLabel <- factor(Spam_SMS$MessageLabel)
```

## Explore the data

Explore the distribution of Spam and Legitimate Messages.
```{r}
# Produce a data frame displaying the total number of legitmate messages and spam messages.
Distribution <- as.data.frame(table(Spam_SMS$MessageLabel))

# Calculate percentage for each type of Message Label. 
Distribution$Percentage <- (Distribution$Freq/nrow(Spam_SMS))*100
Distribution$Percentage <- round(Distribution$Percentage, digits = 2)
names(Distribution) <- c("Label", "Total", "Percentage")

# Plot the Distribution using plotly.
attach(Distribution)

List <- list(
     zeroline=FALSE,
     showline=FALSE,
     showticklabels=FALSE,
     showgrid=FALSE
 )

plot_ly(Distribution, labels=Label, values = Percentage, type="pie", hole=0.2, showlegend = T) %>% layout(title = "Distribution of Spam Messages v/s Legitimate Messages", xaxis=List, yaxis=List, showlegend = TRUE)

```
This plot reveals that 86% of all the SMS messages in the dataset are Legitimate messages, while 13% of them are Spam messages. 

To know the length of each text so as to be able to explore the data more.
```{r}
# Count the number of characters in each Message.
Spam_SMS$MessageLength <- nchar(Spam_SMS$Message)

# Find the maximum length of Legitimate Message.
max(Spam_SMS$MessageLength[Spam_SMS$MessageLabel == "Legitimate"])

# Find the maximum length of Spam Message.
max(Spam_SMS$MessageLength[Spam_SMS$MessageLabel == "Spam"])

# Find the minimum length of Legitimate Message.
min(Spam_SMS$MessageLength[Spam_SMS$MessageLabel == "Legitimate"])

# Find the minimum length of Spam Message.
min(Spam_SMS$MessageLength[Spam_SMS$MessageLabel == "Spam"])
```

Plot the distribution of Legitimate and Spam messages v/s the Message Length.
```{r}
ggplot(Spam_SMS, aes(x = MessageLength, fill = MessageLabel)) +
  theme_bw() +
  geom_histogram(binwidth = 5) +
  labs(y = "Number of Messages", x = "Length of Message",
       title = "Distribution of Message Lengths with Class Labels")
```
This plot helps us understand the following:
1. The length of legitimate messages ranges from 2 characters to 910 characters.
2. The length of spam messages ranges from 13 charcters to 224 characters.
3. The most common length of legitimate messages is 22 characters.
4. The most common length of spam messages is 158 characters.

Split Raw SMS Data on Labels (Spam and Legitmate) and produce wordclouds for each. Using Wordcloud would help understand frequent words. More frequent the word, larger the font will be for it. Producing wordclouds would give a better understanding of all the features that differentiate Spam SMSs from Legitimate SMSs.

```{r}
# Splitting Raw SMS Data on Labels (Spam and Legitmate). 
Spam_Raw <- subset(Spam_SMS, MessageLabel == "Spam")
Legitimate_Raw <- subset(Spam_SMS, MessageLabel == "Legitimate")

# Produce wordcloud for Spam_Raw
pal = brewer.pal(6,"Dark2")
wordcloud(Spam_Raw$Message, max.words = 30, scale=c(6, .3), colors = pal)
```
The wordcloud reveals that the most frequent words in Spam messages are: Call, Free, Now, Mobile, Text, Prize.

```{r}
# Produce wordcloud for Legitimate_Raw
wordcloud(Legitimate_Raw$Message, max.words = 30, scale=c(4, .3), colors = pal)
```
The wordcloud reveals that the most frequent words in legitimate messages are: Can, Will, Now, Just, etc.

To convert all the tokens to lower case. Post that, run for loops for words manually selected as differentiating features for Spam SMSs and for words revealed frequent by the above wordcloud produced for spam messages to correctly assigned 'y' or 'n' for each message in the dataset. ('y' corresponds to availability of that word in a particular SMS while 'n' corresponds to non-availability of that word in the SMS) 
```{r}
# Transformation of all tokens to lower case.
Spam_SMS$Message %<>% str_to_lower()

# For loop for token 'free'
Spam_SMS$free <- "n"
for(i in 1:nrow(Spam_SMS)){
  if(str_detect(Spam_SMS$Message[i], "free")  == TRUE){
    Spam_SMS$free[i] <- "y"
  }
}

# For loop for token 'winner, win, won, award, selected'
Spam_SMS$winner <- "n"
for(i in 1:nrow(Spam_SMS)){
  if(str_detect(Spam_SMS$Message[i], "winner")  == TRUE){
    Spam_SMS$winner[i] <- "y"
  }
  if(str_detect(Spam_SMS$Message[i], "win")  == TRUE){
   Spam_SMS$winner[i] <- "y"
  }
  if(str_detect(Spam_SMS$Message[i], "won")  == TRUE){
   Spam_SMS$winner[i] <- "y"
  }
  if(str_detect(Spam_SMS$Message[i], "award")  == TRUE){
   Spam_SMS$winner[i] <- "y"
    }
    if(str_detect(Spam_SMS$Message[i], "selected")  == TRUE){
   Spam_SMS$winner[i] <- "y"
    }
  if(str_detect(Spam_SMS$Message[i], "prize")  == TRUE){
   Spam_SMS$winner[i] <- "y"
  }
  if(str_detect(Spam_SMS$Message[i], "claim")  == TRUE){
   Spam_SMS$winner[i] <- "y"
  }
}

# For loop for token 'congratulations, congrats'
Spam_SMS$congratulation <- "n"
for(i in 1:nrow(Spam_SMS)){
  if(str_detect(Spam_SMS$Message[i], "congrats")  == TRUE){
    Spam_SMS$congratulation[i] <- "y"
  }
  if(str_detect(Spam_SMS$Message[i], "congratulations")  == TRUE){
    Spam_SMS$congratulation[i] <- "y"
  }
}

# For loop for token 'xxx, babe, naked, dirty, flirty'
Spam_SMS$adult <- "n"
for(i in 1:nrow(Spam_SMS)){
  if(str_detect(Spam_SMS$Message[i], "xxx")  == TRUE){
    Spam_SMS$adult[i] <- "y"
  }
  if(str_detect(Spam_SMS$Message[i], "babe")  == TRUE){
    Spam_SMS$adult[i] <- "y"
  }
  if(str_detect(Spam_SMS$Message[i], "naked")  == TRUE){
    Spam_SMS$adult[i] <- "y"
  }
    if(str_detect(Spam_SMS$Message[i], "dirty")  == TRUE){
    Spam_SMS$adult[i] <- "y"
    }
    if(str_detect(Spam_SMS$Message[i], "flirty")  == TRUE){
    Spam_SMS$adult[i] <- "y"
    }
}

# For loop for token 'urgent, attention, bonus, immediately'
Spam_SMS$attention <- "n"
for(i in 1:nrow(Spam_SMS)){
  if(str_detect(Spam_SMS$Message[i], "urgent")  == TRUE){
    Spam_SMS$attention[i] <- "y"
  }
    if(str_detect(Spam_SMS$Message[i], "attention")  == TRUE){
    Spam_SMS$attention[i] <- "y"
    }
    if(str_detect(Spam_SMS$Message[i], "bonus")  == TRUE){
    Spam_SMS$attention[i] <- "y"
      }
    if(str_detect(Spam_SMS$Message[i], "immediately")  == TRUE){
    Spam_SMS$attention[i] <- "y"
    }
  if(str_detect(Spam_SMS$Message[i], "now")  == TRUE){
   Spam_SMS$attention[i] <- "y"
  }
  if(str_detect(Spam_SMS$Message[i], "stop")  == TRUE){
   Spam_SMS$attention[i] <- "y"
  }
}

# For loop for token 'ringtone'
Spam_SMS$ringtone  <- "n"
for(i in 1:nrow(Spam_SMS)){
  if(str_detect(Spam_SMS$Message[i], "ringtone")  == TRUE){
    Spam_SMS$ringtone[i] <- "y"
  }
  if(str_detect(Spam_SMS$Message[i], "call")  == TRUE){
   Spam_SMS$ringtone[i] <- "y"
  }
  if(str_detect(Spam_SMS$Message[i], "mobile")  == TRUE){
   Spam_SMS$ringtone[i] <- "y"
  }
  if(str_detect(Spam_SMS$Message[i], "text")  == TRUE){
   Spam_SMS$ringtone[i] <- "y"
  }
  if(str_detect(Spam_SMS$Message[i], "txt")  == TRUE){
   Spam_SMS$ringtone[i] <- "y"
  }
}

```
After having this chunk run, there are 6 more columns added to the dataset (Spam_SMS) with values = y or n, depending on the availability of the keywords in messages. 

Plot bar graph depicting total number of messages with the value of these features being equal to "y".
```{r}
#For Unigrams

# Produce a data frame 'Spam_Features' containing Features and the total number of messages containing that feature.
Spam_Features <- data.frame(Features = c("Free", "Adult", "Ringtone", "Congratulation", "Winner", "Attention"), Total = c(sum(Spam_SMS$free == "y"), sum(Spam_SMS$adult == "y"), sum(Spam_SMS$ringtone == "y"), sum(Spam_SMS$congratulation == "y"), sum(Spam_SMS$winner == "y"), sum(Spam_SMS$attention == "y")))

# Plot the data frame.
ggplot(Spam_Features, aes(x = reorder(Features, -Total), y = Total)) + geom_bar(stat = "identity", fill = "steelblue") + geom_text(aes(label = Total), color = "red", vjust = 0) + xlab("Features")+ ylab("Total Number of Messages")
```
The plot reveals that the most frequently used keywords fall under the categories: Ringtone, Attention and Winner, while the least frequently used keywords fall under the categories: Congratulations, Adult and Free. 

Produce Venn Diagram to analyse how many SMS messages have bigrams' feature combination and trigrams' feature combinations.

For bigrams
```{r}
# Compute the number of SMS messages having combination of two and/or three features. After having obtained these values, Venn Diagrams would be produced for these combinations.

#For Free and Adult
Free_Adult <- sum(Spam_SMS$free == "y" & Spam_SMS$adult == "y")
Free_Adult
# Venn Diagram for the bigram
grid.newpage()
draw.pairwise.venn(area1 = 265, area2 = 150, cross.area = 9, category = c("Free", 
    "Adult"), lty = rep("blank", 
    2), fill = c("light blue", "pink"), alpha = rep(0.5, 2), cat.pos = c(0, 
    0), cat.dist = rep(0.025, 2))

#For Free and Ringtone
Free_Ringtone <- sum(Spam_SMS$free == "y" & Spam_SMS$ringtone == "y")
Free_Ringtone
# Venn Diagram for the bigram
grid.newpage()
draw.pairwise.venn(area1 = 265, area2 = 994, cross.area = 193, category = c("Free", 
    "Ringtone"), lty = rep("blank", 
    2), fill = c("light blue", "pink"), alpha = rep(0.5, 2), cat.pos = c(0, 
    0), cat.dist = rep(0.025, 2))

#For Free and Congratulation
Free_Congratulation <- sum(Spam_SMS$free == "y" & Spam_SMS$congratulation == "y")
Free_Congratulation
# Venn Diagram for the bigram
grid.newpage()
draw.pairwise.venn(area1 = 265, area2 = 34, cross.area = 9, category = c("Free", 
    "Congratulation"), lty = rep("blank", 
    2), fill = c("light blue", "pink"), alpha = rep(0.5, 2), cat.pos = c(0, 
    0), cat.dist = rep(0.025, 2))

#For Free and Winner
Free_Winner <- sum(Spam_SMS$free == "y" & Spam_SMS$winner == "y")
Free_Winner
# Venn Diagram for the bigram
grid.newpage()
draw.pairwise.venn(area1 = 265, area2 = 419, cross.area = 52, category = c("Free", 
    "Winner"), lty = rep("blank", 
    2), fill = c("light blue", "pink"), alpha = rep(0.5, 2), cat.pos = c(0, 
    0), cat.dist = rep(0.025, 2))

#For Free and Attention
Free_Attention <- sum(Spam_SMS$free == "y" & Spam_SMS$attention == "y")
Free_Attention
# Venn Diagram for the bigram
grid.newpage()
draw.pairwise.venn(area1 = 265, area2 = 928, cross.area = 104, category = c("Free", 
    "Attention"), lty = rep("blank", 
    2), fill = c("light blue", "pink"), alpha = rep(0.5, 2), cat.pos = c(0, 
    0), cat.dist = rep(0.025, 2))

#For Adult and Winner
Adult_Winner <- sum(Spam_SMS$adult == "y" & Spam_SMS$winner == "y")
Adult_Winner
# Venn Diagram for the bigram
grid.newpage()
draw.pairwise.venn(area1 = 150, area2 = 419, cross.area = 9, category = c("Adult", 
    "Winner"), lty = rep("blank", 
    2), fill = c("light blue", "pink"), alpha = rep(0.5, 2), cat.pos = c(0, 
    0), cat.dist = rep(0.025, 2))

#For Adult and Attention
Adult_Attention <- sum(Spam_SMS$adult == "y" & Spam_SMS$attention == "y")
Adult_Attention
# Venn Diagram for the bigram
grid.newpage()
draw.pairwise.venn(area1 = 150, area2 = 928, cross.area = 29, category = c("Adult", 
    "Attention"), lty = rep("blank", 
    2), fill = c("light blue", "pink"), alpha = rep(0.5, 2), cat.pos = c(0, 
    0), cat.dist = rep(0.025, 2))

#For Congratulation and Winner
congratulation_Winner <- sum(Spam_SMS$congratulation == "y" & Spam_SMS$winner == "y")
congratulation_Winner
# Venn Diagram for the bigram
grid.newpage()
draw.pairwise.venn(area1 = 34, area2 = 419, cross.area = 14, category = c("Congratulation", 
    "Winner"), lty = rep("blank", 
    2), fill = c("light blue", "pink"), alpha = rep(0.5, 2), cat.pos = c(0, 
    0), cat.dist = rep(0.025, 2))

#For Attention and Winner
Attention_Winner <- sum(Spam_SMS$attention == "y" & Spam_SMS$winner == "y")
Attention_Winner
# Venn Diagram for the bigram
grid.newpage()
draw.pairwise.venn(area1 = 928, area2 = 419, cross.area = 161, category = c("Attention", 
    "Winner"), lty = rep("blank", 
    2), fill = c("light blue", "pink"), alpha = rep(0.5, 2), cat.pos = c(0, 
    0), cat.dist = rep(0.025, 2))

#For Ringtone and Winner
Ringtone_Winner <- sum(Spam_SMS$ringtone == "y" & Spam_SMS$winner == "y")
Ringtone_Winner
# Venn Diagram for the bigram
grid.newpage()
draw.pairwise.venn(area1 = 994, area2 = 419, cross.area = 235, category = c("Ringtone", 
    "Winner"), lty = rep("blank", 
    2), fill = c("light blue", "pink"), alpha = rep(0.5, 2), cat.pos = c(0, 
    0), cat.dist = rep(0.025, 2))

#For Ringtone and Congratulation
Ringtone_Congratulation <- sum(Spam_SMS$ringtone == "y" & Spam_SMS$congratulation == "y")
Ringtone_Congratulation
# Venn Diagram for the bigram
grid.newpage()
draw.pairwise.venn(area1 = 994, area2 = 34, cross.area = 23, category = c("Ringtone", 
    "Congratulation"), lty = rep("blank", 
    2), fill = c("light blue", "pink"), alpha = rep(0.5, 2), cat.pos = c(0, 
    0), cat.dist = rep(0.025, 2))

#For Attention and Congratulation
Attention_Congratulation <- sum(Spam_SMS$attention == "y" & Spam_SMS$congratulation == "y")
Attention_Congratulation
# Venn Diagram for the bigram
grid.newpage()
draw.pairwise.venn(area1 = 928, area2 = 34, cross.area = 15, category = c("Attention", 
    "Congratulation"), lty = rep("blank", 
    2), fill = c("light blue", "pink"), alpha = rep(0.5, 2), cat.pos = c(0, 
    0), cat.dist = rep(0.025, 2))

#For Attention and Ringtone
Attention_Ringtone <- sum(Spam_SMS$attention == "y" & Spam_SMS$ringtone == "y")
Attention_Ringtone
# Venn Diagram for the bigram
grid.newpage()
draw.pairwise.venn(area1 = 928, area2 = 994, cross.area = 368, category = c("Attention", 
    "Ringtone"), lty = rep("blank", 
    2), fill = c("light blue", "pink"), alpha = rep(0.5, 2), cat.pos = c(0, 
    0), cat.dist = rep(0.025, 2))

#For Adult and Ringtone
Adult_Ringtone <- sum(Spam_SMS$adult == "y" & Spam_SMS$ringtone == "y")
Adult_Ringtone
# Venn Diagram for the bigram
grid.newpage()
draw.pairwise.venn(area1 = 150, area2 = 994, cross.area = 39, category = c("Adult", 
    "Ringtone"), lty = rep("blank", 
    2), fill = c("light blue", "pink"), alpha = rep(0.5, 2), cat.pos = c(0, 
    0), cat.dist = rep(0.025, 2))
```

For trigrams
```{r}


#For free, congratulation and winner 
Free_Congratulation_Winner <- sum(Spam_SMS$free == "y" & Spam_SMS$congratulation == "y" & Spam_SMS$winner == "y")
Free_Congratulation_Winner
# Venn Diagram for the trigram
grid.newpage()
draw.triple.venn(area1 = 265, area2 = 34, area3 = 419, n12 = 9, n23 = 14, n13 = 52, 
    n123 = 6, category = c("Free", "Congratulation", "Winner"), lty = "blank", 
    fill = c("skyblue", "pink1", "mediumorchid"))

#For free, attention and winner 
Free_Attention_Winner <- sum(Spam_SMS$free == "y" & Spam_SMS$attention == "y" & Spam_SMS$winner == "y")
Free_Attention_Winner
# Venn Diagram for the trigram
grid.newpage()
draw.triple.venn(area1 = 265, area2 = 928, area3 = 419, n12 = 104, n23 = 161, n13 = 52, 
    n123 = 2, category = c("Free", "Attention", "Winner"), lty = "blank", 
    fill = c("skyblue", "pink1", "mediumorchid"))

#For adult, attention and winner 
Adult_Attention_Winner <- sum(Spam_SMS$adult == "y" & Spam_SMS$attention == "y" & Spam_SMS$winner == "y")
Adult_Attention_Winner
# Venn Diagram for the trigram
grid.newpage()
draw.triple.venn(area1 = 150, area2 = 928, area3 = 419, n12 = 29, n23 = 161, n13 = 9, 
    n123 = 3, category = c("Adult", "Attention", "Winner"), lty = "blank", 
    fill = c("skyblue", "pink1", "mediumorchid"))
```
## Text Analysis
To make the data ready for text analysis. In this, we use text-mining package (package tm) to manage the documents.
```{r}
# create a Corpus of Messages in Spam_SMS. 
BagOfWords <- Corpus(VectorSource(Spam_SMS$Message))

# Clean corpus.
Clean_BagOfWords <- BagOfWords %>%
                    tm_map(content_transformer(tolower)) %>% #Transofrm to lower case
                    tm_map(removeNumbers) %>%                #Clean by removing numbers
                    tm_map(removeWords, stopwords(kind="en")) %>% #Clean by removing stopwords
                    tm_map(removePunctuation) %>%            #Clean by removing punctuation
                    tm_map(stripWhitespace)                  #Clean by tokenising by striping white space

# Transform corpus into matrix.
TDM = DocumentTermMatrix(Clean_BagOfWords)

SparseWords <- removeSparseTerms(TDM, 0.995)

# Transform the matrix of Sparsewords into data frame.
SparseWords <- as.data.frame(as.matrix(SparseWords))

# Rename column names.
colnames(SparseWords) <- make.names(colnames(SparseWords))

str(SparseWords)

SparseWords$MessageLabel <- Spam_SMS$MessageLabel

```

## Classification Process to accurately classify SMS messages into Spam messages or Legitimate messages.

Splitting the data in a ratio of 7:3: 70% to build the predictive model and 30% to test the model. I am splitting the dataset, Sparsewords, Corpus(BagOfWords) and the Term Document Matrix(FinalData). 
```{r}
# Random number generation using set.seed of 1234.
set.seed(1234)

# Create a split formula using which I would split the data into train and test sets.
Split_Formula <- createDataPartition(Spam_SMS$MessageLabel, p=0.7, list=FALSE)

# Split Spam_SMS into training and test sets.
train_data <- Spam_SMS[Split_Formula,]
test_data <- Spam_SMS[-Split_Formula,]

# Split SparseWords into training and test sets.
Sparse_train_data <- SparseWords[Split_Formula,]
Sparse_test_data <- SparseWords[-Split_Formula,]

# Split corpus into training and test data.
Corpus_train_data <- Clean_BagOfWords[Split_Formula]
Corpus_test_data <- Clean_BagOfWords[-Split_Formula]

# Split Term Document Matrix into training and test data.
TDM_train_data <- TDM[Split_Formula,]
TDM_test_data <- TDM[-Split_Formula,]


```

Producing Wordcloud of the cleaned Corpus for analysis.
```{r}
wordcloud(Clean_BagOfWords, max.words = 75, random.order = FALSE, scale=c(5, .3), colors = pal)
```
The wordcloud reveals that the most frequent words in Clean Corpus(mix of Legitimate and Spam messages) are: Call, Can, Now, Get, Just, Will, Free, etc. Therefore, it is evident that this wordcloud substantiates the two wordclouds produced above (each for spam an legitimate messages) as this wordcloud has a mix of the frequent words shown in those wordclouds (like: Free, Call, Can, Just)

Split train_data on Labels (Spam and Legitmate) and produce wordclouds for each. Using Wordcloud would help understand frequent words. More frequent the word, larger the font will be for it.
```{r}
# Splitting train_data on Labels (Spam and Legitmate).
Spam <- subset(train_data, MessageLabel == "Spam")
Legitimate <- subset(train_data, MessageLabel == "Legitimate")

# Produce wordcloud for Spam
wordcloud(Spam$Message, max.words = 30, scale=c(7, .3), colors = pal)
```
The wordcloud reveals that the most frequent words in Spam messages for train data are: Call, Free, Now, Claim. Text, etc. They are the same as the ones displayed in the wordcloud for Spam messages in Spam_SMS dataset. Hence, this shows that the data has been correctly splitted into trainng and test sets.


```{r}
# Produce wordcloud for Legitimate.
wordcloud(Legitimate$Message, max.words = 30, scale=c(5, .3), colors = pal)
```
The wordcloud reveals that the most frequent words in Legitimate messages for train data are: Will, Can, Now, Just, etc. they are the same as the ones displayed in the wordcloud for Legitimate messages in Spam_SMS dataset. Hence, this shows that the data has been correctly splitted into trainng and test sets.

## Building models based on the manually selected 6 features of Spam SMS.

## Decision Tree Model
```{r}
# Build a recursive partitioning decision tree.

SMS_Rpart <- rpart(formula = MessageLabel ~ free + winner + congratulation + adult + attention + ringtone, data = train_data, method = "class")

rpart.plot(SMS_Rpart, type = 4, fallen.leaves = FALSE, extra = 4)
```
This tree reveals that out of all these tokens, the most important token is 'ringtone' and the least important ones being 'congratulation and adult'.

```{r}
summary(SMS_Rpart)
```
## Randome Forest Classifier

Apply Random Forest to substantiate analysis of Decision Tree by plotting the importance of each token.
```{r}
train_data$MessageLabel %<>% as.factor()
train_data$Message  %<>% as.character()
train_data$free %<>% as.factor()
train_data$winner %<>% as.factor()
train_data$congratulation %<>% as.factor()
train_data$adult  %<>% as.factor()
train_data$attention   %<>% as.factor()
train_data$ringtone %<>% as.factor()

# Apply the formula for Random Forest Algorithm
SMS_RF <- MessageLabel ~ free + winner + congratulation + adult + attention + ringtone
RFSpam_Tree <- randomForest(SMS_RF, data = train_data, ntree=25, proximity = T)

# Plot the Variable Importance Plot.
ImportancePlot <- varImpPlot(RFSpam_Tree, main = "Importance of each Token") 

```
This plot salso expresses that the most important token aongst all is 'Ringtone', and the least important are 'adult and congratulation'.

```{r}
# Importance of each token in a tabular form.
importance(RFSpam_Tree)
```

Test the above Random Forest Model on test data and check the accuracy, precision, recall and F1.
```{r}
test_data$MessageLabel %<>% as.factor()
test_data$Message  %<>% as.character()
test_data$free %<>% as.factor()
test_data$winner %<>% as.factor()
test_data$congratulation %<>% as.factor()
test_data$adult  %<>% as.factor()
test_data$attention   %<>% as.factor()
test_data$ringtone %<>% as.factor()

RFTest <- predict(RFSpam_Tree, newdata =test_data)

# Confusion Matrix
RF_Matrix <- confusionMatrix(predict(RFSpam_Tree, newdata =test_data), test_data$MessageLabel)
RF_Matrix

# CrossTable
CrossTable(RFTest, test_data$MessageLabel, prop.chisq = FALSE)
```
This classifier has produced a model with:
1. Precision for predicting Legitimate messages is 0.94, while for predicting spam messages is 0.83.
2. Recall for predicting Legitimate messages is 0.98, while for predicting spam messages is 0.63.
Therefore, we can deduce that the probability of predicting  a Legitmate message as a Spam is quite less (0.06) as compared to the probability of a spam message being predicted as a legitimate message (0.17).

Accuracy for test data.
```{r}
TestPredictability <- sum(RFTest == test_data$MessageLabel)/ length(test_data$MessageLabel)*100

message("Accuracy for Test Data is:")
print(TestPredictability)
```
Plot COnfusion Matrix
```{r}

Reference_RF <- factor(c("Legitimate", "Legitimate", "Spam", "Spam"))
Prediction_RF <- factor(c("Legitimate", "Spam","Legitimate","Spam"))
Y <- c(1419, 28, 84, 140)
ConfusionMatrixPlot <- data.frame(Reference_RF, Prediction_RF, Y)

# Plot
ggplot(data =  ConfusionMatrixPlot, mapping = aes(x = Reference_RF, y = Prediction_RF)) +
     geom_tile(aes(fill = Y), colour = "white") +
     geom_text(aes(label = sprintf("%1.0f", Y)), vjust = 1) +
     scale_fill_gradient(low = "yellow", high = "dark green") +
     theme_bw() + theme(legend.position = "none")

```



## Support Vector Machine
```{r}
SMS_SVM <- svm(MessageLabel ~ free + winner + congratulation + adult + attention + ringtone, data = train_data, kernel = "linear", cost = 0.1, gamma = 0.1)
SVMTest <- predict(SMS_SVM, test_data)

# Confusion Matrix
SVM_Matrix <- confusionMatrix(predict(SMS_SVM, newdata = test_data), test_data$MessageLabel)
SVM_Matrix

# CrossTable
CrossTable(SVMTest, test_data$MessageLabel, prop.chisq = FALSE)
```
This classifier has produced a model with:
1. Precision for predicting Legitimate messages is 0.95, while for predicting spam messages is 0.8.
2. Recall for predicting Legitimate messages is 0.98, while for predicting spam messages is 0.65.
Therefore, we can deduce that the probability of predicting  a Legitmate message as a Spam is quite less (0.05) as compared to the probability of a spam message being predicted as a legitimate message (0.19).

Accuracy for test data.
```{r}
svm.accuracy.table <- as.data.frame(table(test_data$MessageLabel, SVMTest))
print(paste("Accuracy for SVM is:",
            100*round(((svm.accuracy.table$Freq[1]+svm.accuracy.table$Freq[4])/nrow(test_data)), 4),
            "%"))

```


Plot confusion matrix.
```{r}
Reference_SVM <- factor(c("Legitimate", "Legitimate", "Spam", "Spam"))
Prediction_SVM <- factor(c("Legitimate", "Spam","Legitimate","Spam"))
Y_SVM <- c(1413, 34, 79, 145)
ConfusionMatrixPlot_SVM <- data.frame(Reference_SVM, Prediction_SVM, Y_SVM)

# Plot
ggplot(data =  ConfusionMatrixPlot_SVM, mapping = aes(x = Reference_SVM, y = Prediction_SVM)) +
     geom_tile(aes(fill = Y), colour = "white") +
     geom_text(aes(label = sprintf("%1.0f", Y)), vjust = 1) +
     scale_fill_gradient(low = "yellow", high = "dark green") +
     theme_bw() + theme(legend.position = "none")
```

## Logistic regression

```{r}
SMS_GLM <- glm(MessageLabel ~ free + winner + congratulation + adult + attention + ringtone, data = train_data, family = "binomial")
GLMTest <- predict(SMS_GLM, test_data, type = 'response')

#Confusion Matrix
GLM_Matrix <- table(test_data$MessageLabel, GLMTest > 0.5)
GLM_Matrix

summary(SMS_GLM)
```
Analysing the summary for Logistic Regression train model, we can infer that:
1. Distribution of residuals is symmetrical. That is, that model can accurately predict points that are close to the actual observed points. 
2. The model reveals that 'congratulation' and 'adult' are the most least important terms as their value of error is far greater than the value of error for Intercept.

Accuracy for test data.
```{r}
#table(test_data$Label, Logistic_Regression_Test > 0.75)
glm.accuracy.table <- as.data.frame(table(test_data$MessageLabel, GLMTest > 0.75))
print(paste("Accuracy of Logistic Regression is:",
            100*round(((glm.accuracy.table$Freq[1]+glm.accuracy.table$Freq[4])/nrow(test_data)), 4),
            "%"))
```

ROCR Curve
```{r}
library(ROCR)
Logistic_Regression_Prediction <- prediction(abs(GLMTest), test_data$MessageLabel)
Logistic_Regression_Performance <- performance(Logistic_Regression_Prediction,"tpr","fpr")
plot(Logistic_Regression_Performance, colorize = TRUE, text.adj = c(-0.2,1.7))
```
The ROCR curve substantiates the high accuracy of the model as the closer the ROC curve is to the upper left corner, the higher the overall accuracy of the test.

##Naive Bayes Classifier
```{r}
#Retain words which appear in 5 or more than 5 SMS messages.
Frequent_Terms = findFreqTerms(TDM_train_data, 5)
TDM_train_data_New = DocumentTermMatrix(Corpus_train_data, list(dictionary=Frequent_Terms))
TDM_test_data_New =  DocumentTermMatrix(Corpus_test_data, list(dictionary=Frequent_Terms))
```

```{r}
#To write a function to convert numerics in TDms to factors of yes/no.
Convert_Numerics_To_Factors = function(num) 
  {
  num = ifelse(num > 0, 1, 0)
  num = factor(num, levels = c(0, 1), labels=c("No", "Yes"))
  return (num)
  }

#Apply above fucntion to the new TDM train and test datasets.
TDM_train_data_New = apply(TDM_train_data_New, MARGIN=2, Convert_Numerics_To_Factors)
TDM_test_data_New  = apply(TDM_test_data_New, MARGIN=2, Convert_Numerics_To_Factors)
```

```{r}
SMS_NB = naiveBayes(MessageLabel ~ free + winner + congratulation + adult + attention + ringtone, data = train_data, laplace = 1)
SMS_NBTest = predict(SMS_NB, TDM_test_data_New)


library(gmodels)
CT <- CrossTable(SMS_NBTest, test_data$MessageLabel, 
           prop.chisq = FALSE, 
           prop.t = FALSE, 
           dnn = c("Predicted", "Actual")) #Name of column
```
This classifier has produced a model with:
1. Precision for predicting Legitimate messages is 0.87, while for predicting spam messages is 1.00.
2. Recall for predicting Legitimate messages is 1.00, while for predicting spam messages is 0.013.
Therefore, we can deduce that the probability of predicting  a Legitmate message as a Spam is high (0.13) as compared to the probability of a spam message being predicted as a legitimate message (0.00).

## Building models for all the features of Spam SMS.

## Decision Tree Model
```{r} 
# Build a recursive partitioning decision tree.
SMS_Rpart_All <- rpart(formula = MessageLabel ~., data = Sparse_train_data, method = "class")

rpart.plot(SMS_Rpart_All, type = 4, fallen.leaves = FALSE, extra = 4)
```
This tree reveals that out of all these tokens, the most important token is 'call' and the least important ones being 'mobile and stop'.

```{r}
summary(SMS_Rpart_All)
```
## Randome Forest Classifier

Apply Random Forest to substantiate analysis of Decision Tree by plotting the importance of each token.
```{r}
Sparse_train_data$MessageLabel %<>% as.factor()

#Applying the formula for Random Forest Algorithm
RFSpam_Tree_All <- randomForest(MessageLabel~., data = Sparse_train_data, ntree=25, proximity = T)

#To plot the Variable Importance Plot.
ImportancePlot <- varImpPlot(RFSpam_Tree_All, n.var=min(10, nrow(RFSpam_Tree_All$importance), main = "Importance of each Token"))

```
This plot also expresses that the most important token amongst all is 'Call'.

```{r}
# Importance of each token in a tabular form.
importance(RFSpam_Tree_All)
```

Test the above Random Forest Model on test data and check the accuracy, precision, recall and F1.
```{r}
Sparse_test_data$MessageLabel %<>% as.factor()

RFTest_All <- predict(RFSpam_Tree_All, newdata =Sparse_test_data)

# Confusion Matrix
RFTest_Matrix_All <- confusionMatrix(predict(RFSpam_Tree_All, newdata =Sparse_test_data), Sparse_test_data$MessageLabel)
RFTest_Matrix_All

# CrossTable
CrossTable(RFTest_All, test_data$MessageLabel, prop.chisq = FALSE)
```
This classifier has produced a model with:
1. Precision for predicting Legitimate messages is 0.97, while for predicting spam messages is 0.94.
2. Recall for predicting Legitimate messages is 0.99, while for predicting spam messages is 0.78.
Therefore, we can deduce that the probability of predicting  a Legitmate message as a Spam is quite less (0.03) as compared to the probability of a spam message being predicted as a legitimate message (0.64).


Accuracy for test Data.
```{r}
TestPredictability_All <- sum(RFTest_All == Sparse_test_data$MessageLabel)/ length(Sparse_test_data$MessageLabel)*100

message("Predcitability Percentage for Test Data is:")
print(TestPredictability_All)
```

Plot Confusion Matrix
```{r}

Reference_RF_All <- factor(c("Legitimate", "Legitimate", "Spam", "Spam"))
Prediction_RF_All <- factor(c("Legitimate", "Spam","Legitimate","Spam"))
Y_All <- c(1435, 49, 12, 175)
ConfusionMatrixPlot_All <- data.frame(Reference, Prediction, Y)

# Plot
ggplot(data =  ConfusionMatrixPlot_All, mapping = aes(x = Reference_RF_All, y = Prediction_RF_All)) +
     geom_tile(aes(fill = Y), colour = "white") +
     geom_text(aes(label = sprintf("%1.0f", Y)), vjust = 1) +
     scale_fill_gradient(low = "yellow", high = "dark green") +
     theme_bw() + theme(legend.position = "none")

```

## Support Vector Machine

```{r}
SMS_SVM_All <- svm(MessageLabel ~., data = Sparse_train_data, kernel = "linear", cost = 0.1, gamma = 0.1)
SVMTest_All <- predict(SMS_SVM_All, Sparse_test_data)

# Confusion Matrix
SVM_Measure_All <- confusionMatrix(predict(SMS_SVM_All, newdata = Sparse_test_data), Sparse_test_data$MessageLabel)

# CrossTable
CrossTable(SVMTest_All, Sparse_test_data$MessageLabel, prop.chisq = FALSE)
```
This classifier has produced a model with:
1. Precision for predicting Legitimate messages is 0.98, while for predicting spam messages is 0.85.
2. Recall for predicting Legitimate messages is 0.98, while for predicting spam messages is 0.88.
Therefore, we can deduce that the probability of predicting  a Legitmate message as a Spam is quite less (0.02) as compared to the probability of a spam message being predicted as a legitimate message (0.15).

Accuracy for test data.
```{r}
svm.accuracy.table_All <- as.data.frame(table(Sparse_test_data$MessageLabel, SVMTest_All))
print(paste("Accuracy for SVM is:",
            100*round(((svm.accuracy.table_All$Freq[1]+svm.accuracy.table_All$Freq[4])/nrow(Sparse_test_data)), 4),
            "%"))

```

Plot Confusion Matrix
```{r}

Reference_SVM_All <- factor(c("Legitimate", "Legitimate", "Spam", "Spam"))
Prediction_SVM_All <- factor(c("Legitimate", "Spam","Legitimate","Spam"))
Y_SVM_All <- c(1412, 35, 28, 196)
ConfusionMatrixPlot_SVM_All <- data.frame(Reference_SVM_All, Prediction_SVM_All, Y_SVM_All)

# Plot
ggplot(data =  ConfusionMatrixPlot_SVM_All, mapping = aes(x = Reference_SVM_All, y = Prediction_SVM_All)) +
     geom_tile(aes(fill = Y), colour = "white") +
     geom_text(aes(label = sprintf("%1.0f", Y)), vjust = 1) +
     scale_fill_gradient(low = "yellow", high = "dark green") +
     theme_bw() + theme(legend.position = "none")

```

Logistic Regression
```{r}
SMS_GLM_All <- glm(MessageLabel ~., data = Sparse_train_data, family = "binomial")
GLMTest_All <- predict(SMS_GLM_All, Sparse_test_data, type = 'response')

#Confusion Matrix
GLM_Matrix_All <- table(Sparse_test_data$MessageLabel, GLMTest_All > 0.5)
GLM_Matrix_All

summary(SMS_GLM_All)
```
Analysing the summary for Logistic Regression train model, we can infer that:
1. Distribution of residuals is not so symmetrical. That is, that model is also predicting points far away from the actual observed points. 
2. The model reveals that 'call' is the most important terms as its value of error is same as the value of error for Intercept.

Accuracy for test data.
```{r}
glm.accuracy.table.All <- as.data.frame(table(Sparse_test_data$MessageLabel, GLMTest_All > 0.75))
print(paste("Accuracy of Logistic Regression is:",
            100*round(((glm.accuracy.table.All$Freq[1]+glm.accuracy.table.All$Freq[4])/nrow(Sparse_test_data)), 4),
            "%"))
```

ROCR Curve
```{r}
library(ROCR)
Logistic_Regression_Prediction_All <- prediction(abs(GLMTest_All), Sparse_test_data$MessageLabel)
Logistic_Regression_Performance_All <- performance(Logistic_Regression_Prediction_All,"tpr","fpr")
plot(Logistic_Regression_Performance_All, colorize = TRUE, text.adj = c(-0.2,1.7))
```
The ROCR curve substantiates the high accuracy of the model as the closer the ROC curve is to the upper left corner, the higher the overall accuracy of the test.

## Naive Bayes Model

```{r}
SMS_NB_All = naiveBayes(MessageLabel ~. , data = Sparse_train_data, laplace = 1)
SMS_NBTest_All = predict(SMS_NB_All, TDM_test_data_New)


library(gmodels)
CT <- CrossTable(SMS_NBTest_All, Sparse_test_data$MessageLabel, 
           prop.chisq = FALSE, 
           prop.t = FALSE, 
           dnn = c("Predicted", "Actual")) #Name of column
```
Accurately predicted all the legitimate and spam messages.